# Ollama (OpenAI-compatible)
OPENAI_API_KEY=ollama

# Default/Quality Embedder Configuration
OPENAI_BASE_URL=http://100.76.6.21:11435/v1 # http://host.docker.internal:11435/v1
MODEL_NAME=qwen3:30b-a3b-instruct-2507-q4_K_M

# Embedding Configuration
# Set to 4096 to support full dimensionality for models like Qwen3-Embedding. 
# Models with lower dimensions (like Nomic at 768) will still work correctly.
EMBEDDING_DIM=4096

# Dedicated URL for quality embedding (optional, fallbacks to openai_base_url if not set)
EMBEDDING_BASE_URL=http://100.76.6.21:11435/v1
EMBEDDING_MODEL=qwen3-embedding:8b-q8_0  # qwen3-embedding:4b

# Fast Embedder Configuration (optional, defaults to embedding_base_url if not set)
FAST_BASE_URL=http://host.docker.internal:11434/v1
FAST_EMBEDDING_MODEL=nomic-embed-text:latest


TS_AUTHKEY=


# For Docker Compose (required)
NEO4J_AUTH=neo4j/password

# For Local Development Only (not needed when running in Docker)
# Uncomment these if running the app directly outside Docker:
# NEO4J_URI=bolt://localhost:7687
# NEO4J_USER=neo4j
# NEO4J_PASSWORD=password
# NEO4J_FAST_URI=bolt://localhost:7787
